<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cryptic Crossword Evaluation Results</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Cryptic Crossword Evaluation Benchmark</h1>
            <p class="subtitle">Evaluating Large Language Models on Cryptic Crossword Solving</p>
        </header>

        <section class="abstract">
            <h2>About This Benchmark</h2>
            <p>
                This benchmark evaluates how well LLMs can solve cryptic crossword clues. At the start of 2025 I decided to try to get better at cryptic crosswords. Naturally, I attempted to use LLMs to help me by getting them to explain the clues and answers when I was stuck. What I found was that (at that time) LLMs were pretty bad at solving cryptic crosswords - they would often take illogical reasoning steps resulting in the wrong answer, or even when given the answer they would come up with spurious reasoning as to how to get there.
            </p>
            <p>
                Solving cryptic crosswords requires a combination of knowledge & lateral thinking. Each clue is a short sentence with some part containing the <i>definition</i> for the answer, and the rest containing <i>wordplay</i> of some sort, usually made up of <i>indicator </i> words donating a manipulation to do (eg. anagram, take the first letters, etc.) and <i>fodder</i> - the word(s) to apply the manipulation to. Therefore they are a good testbed to assess a model's ability to reason and think logically using some amount of world knowledge. Although cryptic crosswords often invovle knowing specific terminology or tricks, one would expect current LLMs to have stored this and any other general knowledge required. Therefore this tests the ability of applying that base knowledge in a logical way to solve the puzzle.
            </p>
            <p>
                Being able to solve cryptic crossword clues is not sufficient to demonstrate intelligence - it tests applying laterial thinking in a very specific instance and there are many other attributes of intellegince it does not test. However, I would argue that is is at least indicative of one core attribute of intelligence: the ability to reason and think logically.
            </p>
        </section>

        <section class="results-section">
            <h2>Results</h2>

            <div id="loading" class="loading">
                <p>Loading results...</p>
            </div>

            <div id="no-results" class="no-results" style="display: none;">
                <p>No evaluation results available yet.</p>
                <p class="hint">Run an evaluation to see results here:</p>
                <code>uv run python eval/run_and_save.py --model anthropic/claude-sonnet-4-20250514</code>
            </div>

            <div id="results-content" style="display: none;">
                <div class="chart-container">
                    <canvas id="accuracyChart"></canvas>
                </div>

                <div class="table-container">
                    <table id="results-table">
                        <thead>
                            <tr>
                                <th>Rank</th>
                                <th>Model</th>
                                <th>Accuracy</th>
                                <th>Samples</th>
                                <th>Model Args</th>
                                <th>Date</th>
                            </tr>
                        </thead>
                        <tbody id="results-body">
                        </tbody>
                    </table>
                </div>
            </div>
        </section>

        <section class="methodology">
            <h2>Methodology</h2>
            <ul>
                <li><strong>Dataset:</strong> Cryptic crossword clues were taken from The Times during January 2026. They include 4 Quick Cryptic puzzles and 4 full Cryptic puzzles, giving a total of 195 clues.</li>
                <li><strong>Prompt:</strong> Each clue is presented with the answer length hint. The model is then asked to solve the clue and provide the answer.</li>
                <li><strong>Scoring:</strong> Each clue is scored according to whether it is an exact match to the ground truth answer after normalisation (case-insensitive, alphanumeric only). The accuracy is the percentage of clues that are solved correctly.</li>
            </ul>
        </section>

        <footer>
            <p>
                <a href="https://github.com/ddathan/cryptic-crossword-bench">View on GitHub</a>
            </p>
            <p class="generated-at" id="generated-at"></p>
        </footer>
    </div>

    <script src="app.js"></script>
</body>
</html>
